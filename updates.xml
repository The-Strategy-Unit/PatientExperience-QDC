<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>PatientExperience-QDC website</title>
<link>https://CDU-data-science-team.github.io/PatientExperience-QDC/updates.html</link>
<atom:link href="https://CDU-data-science-team.github.io/PatientExperience-QDC/updates.xml" rel="self" type="application/rss+xml"/>
<description>Website for the NHS England funded Patient Experience Qualitative Data Categorisation project</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Tue, 18 Jul 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Using an upset plot to explore the relationship between large categorical data</title>
  <dc:creator>Oluwasegun Apejoye</dc:creator>
  <link>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/upset_plot-23-07-18/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>An upset plot is a great visualisation tool that can be used to show and understand the relationships and associations between large categories (called sets) in data. It shows the number of elements (number of comments in our case) the set (sub-categories) have in common and visualise it nicely using a matrix layout and a series of bar charts. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/annotated_Upset_plot.jpg"><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/upset_plot-23-07-18/images/annotated_Upset_plot.jpg" class="img-fluid figure-img" alt="An annotated upset plot"></a></p>
<figcaption class="figure-caption">Upset plot (click on the image to expand it)</figcaption>
</figure>
</div>
<section id="how-is-it-plotted" class="level3">
<h3 class="anchored" data-anchor-id="how-is-it-plotted">How is it plotted?</h3>
<p>To plot an upset plot the data has to be prepared. Using our use case as an example, we prepared the data in this way:</p>
<ul>
<li><p>Every record (row) represents one comment</p></li>
<li><p>Each column represents a label with a yes/no flag as to whether or not that comment was assigned the label. It is coded 1 for “yes” and 0 for “no”,</p></li>
<li><p>All the label names are used as the attribute on the plot.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/upset-data.jpg"><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/upset_plot-23-07-18/images/upset-data.jpg" class="img-fluid figure-img" alt="sample data for upset plot"></a></p>
<figcaption class="figure-caption">Sample data for upset plot (click on the image to expand it)</figcaption>
</figure>
</div>
</section>
<section id="why-upset-plot-and-how-should-it-be-used" class="level3">
<h3 class="anchored" data-anchor-id="why-upset-plot-and-how-should-it-be-used">Why Upset plot and how should it be used?</h3>
<p>In this project, we assign labels (sub-categories) to free text comments in a way that one comment can have 1 or more labels assigned to it. Upset plots provide a way to show the relationship between the assigned labels simultaneously. By exploring this pattern we can identify groups of categories that are mostly discussed together in a single comment. This plot can guide us as we explore answers to questions such as this:</p>
<p><em>Do most comments about staff “competence &amp; training” also relate to the “provision of medical equipment”?</em></p>
<p>This plot is used in the dashboard as a visual guide to help users as they explore the free text comments. The plot can be used to gain insight into the sub-categories that people might talk about more frequently within the same comments. However, the fact that people talk about a group of sub-categories in the same comment doesn’t mean those sub-categories have a relationship in reality, and that is why we provide functionality within the dashboard for users to further explore the free text comments. The comments should be read to explore explanations for any pattern seen on the visual and to carry out any additional qualitative analysis as required.</p>


</section>
</section>

 ]]></description>
  <category>news</category>
  <guid>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/upset_plot-23-07-18/index.html</guid>
  <pubDate>Tue, 18 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/upset_plot-23-07-18/images/annotated_Upset_plot.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Experience Dashboard at Version 0.7.0: A data exploration tool</title>
  <dc:creator>Oluwasegun Apejoye</dc:creator>
  <link>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/dashboard-update-23-07-18/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Our first update on the dashboard was based on version 0.6 of the dashboard. And we noted then that we would be rolling out some features into the dashboard. We are glad to say that we implemented some changes and added new features, in version 0.7 series of the dashboard, which we believe have added some elegance to the dashboard and improved its usefulness as a data exploration and visualisation tool to help clinicians, ward managers, and general users identify the pattern in free text data and to access the underlying comments to explore explanations for any pattern seen on the visual.</p>
</section>
<section id="new-or-updated-features" class="level2">
<h2 class="anchored" data-anchor-id="new-or-updated-features">New or updated features</h2>
<p>In this section, I will provide a high-level overview of the changes we made and the additional features we introduced.</p>
<p><strong>Move from single-labelling to multi-labelling of comments:</strong> This is the main highlight of all the changes that we introduced. Multi-tagging of patient comments is a crucial part of this phase of the patient experience data categorisation project. The dashboard has always supported single labelled categories but we have now improved the dashboard to support multi-labelled sub-categories and categories (also called super-category in this post). The data format of the dashboard underlining data has also changed to accommodate these changes.</p>
<p><strong>Adoption of the NHS Identity:</strong> We made every effort to change the general dashboard theme and visualisation colours to follow the <a href="https://www.england.nhs.uk/nhsidentity/">NHS Identity</a>. This was done to provide consistency between the dashboard and other NHS-related dashboards since the dashboard is targeted at NHS-related organisations. Note: This project is still open source and can be used by anyone as far as you follow the <a href="https://github.com/CDU-data-science-team/experiencesdashboard/blob/documentation/LICENSE.md">MIT Licence</a> under which this work is distributed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/landing_page.png"><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/dashboard-update-23-07-18/images/landing_page.png" class="img-fluid figure-img" alt="New Landing Page"></a></p>
<figcaption class="figure-caption">Fig 1. New Landing Page</figcaption>
</figure>
</div>
<p><strong>Update SPC Chart of the FFT Scores:</strong> We used the <a href="https://github.com/nhs-r-community/NHSRplotthedots">NHSR plotthedots package</a> to draw the SPC (statistical process control) chart. The now follows the principles laid out in the NHSE programme, <a href="https://www.england.nhs.uk/publication/making-data-count/">‘Making Data Count’</a>, and allows users to easily see change points, and identify when rules are breached.</p>
<p><strong>Use Upset plot instead of HeatMap to visualise inter-relationships between sub-categories</strong>: Using an upset plot allows users to see the relationships and associations between the large sub-categories (over 40 different sub-categories) present in the data. <a href="../../posts/upset_plot-23-07-18/index.html">Read more here</a></p>
<p><strong>QDC Framework</strong>: The landing page now contains a high-level overview of the data categorisation framework developed as part of this project and implemented to assign the sub-categories to the free text comments. see the <a href="../../framework/index.html">framework</a> for more details.</p>
<p><strong>Visualise trends in sub-categories</strong>: We added a plot to visualise the distribution of comments over time.</p>
<p><strong>Implement the Pxtextming API</strong>: We implemented the <a href="../../posts/update-23-05-31/index.html">pxtextmining API</a> for machining learning tasks (predicting the sub-categories). Using the API was a more efficient way to interact with the Python machine learning model compared to the previous implementation which requires installing the R version of the pxtextmining package, <code>pxtextmineR</code>, <code>reticulate</code> and downloading the actual Python models needed for the prediction.</p>
<p><strong>Download complex comments</strong> <strong>and other data</strong>: We added the functionality to download the complex comment for further analysis. Also, users can now download the underline data serving the visualisation they interact with. They can also download all the historical data that serve the dashboard.</p>
<p><strong>Filter with Demographic features</strong>: Users can now drill down into the data using three demographic features such as age, sex, and ethnicity. This alongside the location and date filter will allow users to drill down the data to their target population and analyse further.</p>
</section>
<section id="future-work" class="level2">
<h2 class="anchored" data-anchor-id="future-work">Future work</h2>
<p>As we progress, we eagerly embrace the invaluable feedback from the dashboard users. Our commitment to agility remains steadfast, allowing us to efficiently incorporate and implement the essential updates inspired by users’ feedback, to make sure the dashboard consistently meets their evolving needs. We’ll continue to refine and enrich the dashboard’s features to achieve optimal performance and user satisfaction.</p>


</section>

 ]]></description>
  <category>news</category>
  <category>dashboard</category>
  <guid>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/dashboard-update-23-07-18/index.html</guid>
  <pubDate>Tue, 18 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/dashboard-update-23-07-18/images/landing_page.png" medium="image" type="image/png" height="73" width="144"/>
</item>
<item>
  <title>pxtextmining API: enabling access to project outputs</title>
  <dc:creator>YiWen Hon</dc:creator>
  <link>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/index.html</link>
  <description><![CDATA[ 



<p>Our latest major project milestone is the release of a model API. This blog post will explain what this is, how we have achieved it, and what our next steps are.</p>
<section id="what-is-an-api" class="level2">
<h2 class="anchored" data-anchor-id="what-is-an-api">What is an API?</h2>
<p>API stands for “application programming interface”. Most of the digital services and platforms that we use have an API. It is essentially a gateway that allows access to information. For example, when you ask an Alexa or Siri what the weather is, it will communicate with a weather service API to obtain the information for you. When you get an email notification on your phone, this is because your email service provider is sending a notice via its API, to your phone.</p>
<p>Still confused? <a href="https://youtu.be/s7wmiS2mSXY">This video</a> may help.</p>
<p>The pxtextmining API allows people to utilise the machine learning models that we have trained for the project to label new text. It makes the model accessible over the internet, without any installation or downloads required. All that’s needed is a few lines of code. Examples are available on the <a href="https://cdu-data-science-team.github.io/pxtextmining/reference/API/API/">pxtextmining documentation website</a>.</p>
</section>
<section id="why-did-we-do-it" class="level2">
<h2 class="anchored" data-anchor-id="why-did-we-do-it">Why did we do it?</h2>
<p>The API was created to separate our R/Shiny-based experiencesdashboard frontend and the Python-based pxtextmining backend. This independence means more flexibility in the development of each. This also means that some participating trusts can utilise the model only, if they wish, and integrate it into their existing visualisation tools/dashboards for exploring patient feedback data.</p>
<p>We also recognise that although the code and models for pxtextmining are available openly on github, many organisations may not have the technical resources, time, or capability to run it themselves. Making the model available via an API reduces the barrier to entry and ensures that the project outputs are more accessible.</p>
</section>
<section id="how-did-we-do-it" class="level2">
<h2 class="anchored" data-anchor-id="how-did-we-do-it">How did we do it?</h2>
<p>The API is built using the open source <a href="https://fastapi.tiangolo.com/lo/">Python FastAPI package</a>. Users of the API must format their data in JSON format, and submit this to the API endpoint via a POST request. This then gets cleaned and passed through the machine learning model, and the outputted labels are returned, also in JSON format. We utilised the <a href="https://www.uvicorn.org/">Uvicorn</a> library to test the API locally, and have ensured that the API is covered by unit tests. We are hosting the API on the Strategy Unit’s Rstudio Connect server. Deploying it was very simple, luckily! The diagram below shows how the API works.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/px_diagram.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Diagram of API</figcaption>
</figure>
</div>
</section>
<section id="whats-next" class="level2">
<h2 class="anchored" data-anchor-id="whats-next">What’s next?</h2>
<p>The API currently uses a <a href="https://youtu.be/efR1C6CvhmE">support vector classifier</a> model which is quite small and fast. Even so, we have to balance the load on the server with waiting times, limiting the number of requests to 1000 at a time to prevent timeouts. We also have a <a href="https://youtu.be/SZorAJ4I-sA">transformer-based model</a> which is very large and slow, taking several minutes to make predictions from text, which we have not implemented an API for. Our next step is to figure out how to do this without completely taking over the server’s resources, and impacting too much on the user experience.</p>
<p>We also want to make sure that participating trusts are able to make use of the API, and help demystify it. Communication is key, and blog posts like this will hopefully help. We are also providing example scripts showing how to create API queries in R and Python, and have built a <a href="https://connect.strategyunitwm.nhs.uk/content/0049176a-56d7-40c9-bf07-26262e9ee53c">simple website</a> that shows the API and the model in action.</p>
<p>The model that is used in the API is also still a work in progress, we know we have a lot of work to do to improve performance. But now that the technical infrastructure is in place, it should be relatively easy to update with new models, when we train them. If you’re interested in using the API, do get in touch!</p>


</section>

 ]]></description>
  <category>news</category>
  <guid>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/index.html</guid>
  <pubDate>Wed, 31 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/px_diagram.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Machine learning update</title>
  <dc:creator>YiWen Hon</dc:creator>
  <link>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/index.html</link>
  <description><![CDATA[ 



<p>We’ve had a chance to play around with a few different model architectures now and the main finding is that so far, as in Phase 1 and other <a href="https://www.sciencedirect.com/science/article/pii/S1386505621002689?via%3Dihub">similar projects</a>, Support Vector Classifier is performing the best. We are currently prototyping using only some of the final dataset, and focusing on predicting 1 of 13 overarching ‘major categories’. These are divided into a further 50+ subcategories, which our models are not yet trained to detect, but this will be the next step, once the framework is finalised.</p>
<p>We have also tried out Distilbert uncased, which is performing well, if not slightly better, than SVC. However, it’s taking a long time to train (around 6 hours on average) and is very large, around 1 GB in size. It also takes a long time to make predictions, around 1 minute per 1000 comments. When we have the final dataset we’ll have a clearer picture of which model will be best suited for the needs of the project.</p>
<p>The latest development is that we’re able to combine the text with the ‘question type’ feature. Most of the questions asked by trusts can be divided into one of three main types:</p>
<ul>
<li><p>What did we do well?</p></li>
<li><p>What could we do better?</p></li>
<li><p>Any other comments / no specific question</p></li>
</ul>
<p>Including the question type with the text of the comment has improved performance slightly. The way this has been done with BERT can be seen in the diagram below. We tried both of the methods found in <a href="https://stackoverflow.com/a/73576407/17852099">this stackoverflow post</a>, which produced similar results. We went for the concatenated layers, however, as this means the model architecture is more flexible and can be adapted to include other features as well, if necessary.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/model_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Distilbert model with categorical question type feature</figcaption>
</figure>
</div>



 ]]></description>
  <category>news</category>
  <guid>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/index.html</guid>
  <pubDate>Mon, 13 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/model_architecture.png" medium="image" type="image/png" height="107" width="144"/>
</item>
</channel>
</rss>
